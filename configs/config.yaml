# configs/config.yaml

general:
  # WARNING: Using env variables (export HF_TOKEN=...) is safer
  hf_access_token: ""
  cache_dir: "./.cache"

output:
  base_dir: "./results" 

models:
  "1.5B":
    model_name: "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"
  "7B":
    model_name: "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B"
  "phi-4-mini-reasoning":
    model_name: "microsoft/Phi-4-mini-reasoning"
  "qwen30p6":
    model_name: "Qwen/Qwen3-0.6B"

datasets:
  "aime24":
    dataset_name: "Maxwell-Jia/AIME_2024"
    split: "train"
    prompt_key: "Problem"    
    answer_key: "Answer"     
    prompt_tail: " Please reason step by step, and put your final answer within \\boxed{}."

  "aime25":
    dataset_name: "math-ai/AIME25"
    split: "test"
    prompt_key: "problem"    
    answer_key: "answer"    
    prompt_tail: " Please reason step by step, and put your final answer within \\boxed{}."

  "MATH500":
    dataset_name: "HuggingFaceH4/MATH-500"
    split: "test"
    prompt_key: "problem"    
    answer_key: "answer"     
    prompt_tail: " Please reason step by step. At the end, output ALL required final answers inside a single LaTeX tuple inside ONE \\boxed{ }."

  "gpqa_diamond":
    dataset_name: "Idavidrein/gpqa"
    split: "train"
    prompt_key: "Question"  
    answer_key: "Correct Answer" 
    prompt_tail: ""
  
  "livebench_reasoning":
    dataset_name: "livebench/reasoning"
    split: "test"
    prompt_key: "turns"
    answer_key: "ground_truth"
    prompt_tail: ""
